{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the model\n",
    "\n",
    "We settled on Random Forest Regressor model. Let us fintune the hyper-parameters if it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data_transformer import ca_housing_data_transformer\n",
    "from ca_housing_data import CAHousingData\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "Read the original housing data in the DataFrame. Delete the target feature column `median_house_value`.\n",
    "Extract the `numerical_cols` and `categorical_col` names to be used in the Data Preprocessing stage.\n",
    "1. `numerical_cols` will be used:\n",
    "    - ZeroToNaNTransformer: Convert '0' to NaN values, to be replaced by median for that column later\n",
    "    - SimpleImputer: Replace all NaN by median for that column\n",
    "    - PerHouseholdFeaturesAdder: Add three more attributes per household.\n",
    "    - Standard scaling of all the numerical columns\n",
    "2. `categorical_col`: 'ocean_proximity' will be replaced by OHE. In the test data the startegy will be 'infrequent_if_exist'. Replace a unknown category by infrequent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read saved data\n",
    "housing_data = CAHousingData()\n",
    "housing_labels = housing_data.labels()  # Target value to be predicted\n",
    "housing_features = housing_data.features()  # Features to be used for prediction\n",
    "housing_feature_names = housing_features.columns.tolist()  # Used to rank the features\n",
    "numerical_cols = housing_data.numerical_features()\n",
    "categorical_col = housing_data.categorical_features()\n",
    "ocean_categories = housing_data.ocean_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\", \".join(housing_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\", \".join(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods\n",
    "These handy methods are used to simplify the code and reuse:\n",
    "1. `print_results`: Print, best score, params and estimator\n",
    "2. `print_feature_rank`: Relative feature rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(search_results):\n",
    "    \"\"\"Print the results of the search.\"\"\"\n",
    "    print(f\"Best score: {search_results.best_score_:,.2f}\")\n",
    "    print(f\"Best parameters: {search_results.best_params_}\")\n",
    "    print(f\"Best estimator: {search_results.best_estimator_}\")\n",
    "    cv_results = search_results.cv_results_\n",
    "    for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "        print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_rank(feature_importances, feature_names):\n",
    "    \"\"\"Print the feature rank.\n",
    "\n",
    "    \"\"\"\n",
    "    feature_rank = sorted(\n",
    "        zip(feature_importances, feature_names), reverse=True)\n",
    "    print(\"Feature rank:\")\n",
    "    for rank, (importance, feature) in enumerate(feature_rank):\n",
    "        print(f\"  {rank + 1:02d}. {feature}: {importance:,.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_params(best_params):\n",
    "    \"\"\"Print the best parameters of the model.\"\"\"\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = ca_housing_data_transformer(\n",
    "    numerical_cols, categorical_col, ocean_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remark:__ Note that the scikit-learn parameter has a specific grid naming convention.\n",
    " - `step_name__parameter_name`: Use double underscores `(__)` to separate step name from parameter name\n",
    " - \n",
    " - Example `preprocessor__num_pipeline__imputer__strategy`:\n",
    "    - preprocessor: Name of the ColumnTransformer step\n",
    "    - num_pipeline: Name of the numerical pipeline\n",
    "    - imputer: Name of the SimpleImputer step\n",
    "    - strategy: The actual parameter name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Random Forest on all the data.\n",
    "rf_cv_pipeline = Pipeline([\n",
    "    ('preprocessor', data_processor),\n",
    "    ('model', RandomForestRegressor(random_state=282))\n",
    "])\n",
    "# For GridSearchCV\n",
    "param_grid = [\n",
    "    # try 3 x 4 = 12 combinations of hyperparameters\n",
    "    # (3, 2), (3, 4), (3, 6), (3, 8), ...\n",
    "    {\n",
    "        'model__n_estimators': [3, 10, 30],\n",
    "        'model__max_features': [2, 4, 6, 8],\n",
    "        'preprocessor__num_pipeline__imputer__strategy': ['mean', 'median']\n",
    "    },\n",
    "    # Then try 2 x 3 = 6 combinations with bootstrap set to False\n",
    "    # (3, 2), (3, 3), (3, 4), (10, 2), (10, 3), (10, 4)\n",
    "    {\n",
    "        'model__bootstrap': [False],\n",
    "        'model__n_estimators': [3, 10],\n",
    "        'model__max_features': [2, 3, 4]\n",
    "    }\n",
    "]\n",
    "# 5 folds, for each combination of hyperparameters, 5 x 12 = 60 models\n",
    "grid_search = GridSearchCV(\n",
    "    rf_cv_pipeline, param_grid, cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    return_train_score=True\n",
    ")\n",
    "grid_search = grid_search.fit(housing_features, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances is an attribute of the RandomForestRegressor\n",
    "best_model = grid_search.best_estimator_\n",
    "# Access feature importances through the model step\n",
    "feature_importances = best_model.named_steps['model'].feature_importances_\n",
    "print_feature_rank(feature_importances, housing_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters\n",
    "print_best_params(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    # Model parameters\n",
    "    'model__n_estimators': randint(low=100, high=500),  # Increased range\n",
    "    'model__max_features': randint(low=1, high=8),\n",
    "    'model__max_depth': randint(low=5, high=30),\n",
    "    'model__min_samples_split': randint(low=2, high=20),\n",
    "    'model__min_samples_leaf': randint(low=1, high=10),\n",
    "    'model__bootstrap': [True, False],\n",
    "\n",
    "    # Preprocessing parameters\n",
    "    'preprocessor__num_pipeline__imputer__strategy': ['mean', 'median']\n",
    "}\n",
    "random_search = RandomizedSearchCV(rf_cv_pipeline,\n",
    "                                   param_distributions=param_distribs,\n",
    "                                   n_iter=10, cv=5,\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   random_state=282)\n",
    "random_search = random_search.fit(housing_features, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "feature_importances = best_model.named_steps['model'].feature_importances_\n",
    "print_feature_rank(feature_importances, housing_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_best_params(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model\n",
    "\n",
    "## Model Confidence\n",
    "\n",
    "Compute the confidence range. \n",
    "We are 95% confident that the model true RMSE of the model is between these two numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything (preferred for analysis and reproducibility)\n",
    "# The search.predict(X_test) will run on the\n",
    "#   search.best_estimator_.predict(X_test)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(random_search, \"../../data/random_forest_regressor.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
