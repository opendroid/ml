{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try various models\n",
    "This exercise:\n",
    "1. Prepares the data for the models\n",
    "2. Run various models and error estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for models\n",
    "\n",
    "Undering the data in step 1, look at various X_train, X_test samples to create to test models.\n",
    "We shall look at random and startified train/test samples.\n",
    "\n",
    "Here are the step we will perform:\n",
    "\n",
    "1. Create a numeris pipeline that\n",
    "    - Imputes the numerical columns with median strategy for numerical columns \n",
    "    - Adds three more columns (add custom transformer):\n",
    "        - rooms_per_household = total_rooms / households\n",
    "        - population_per_household = population / households\n",
    "        - bedrooms_per_room = total_bedrooms / total_rooms\n",
    "    - Scales all numerical columns\n",
    "2. Perform One Hot Encoding on ocean_proximity \n",
    "3. Drop ocean_proximity from training and labels\n",
    "4. Perform startification on \"income_cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging first\n",
    "import logging\n",
    "\n",
    "# Configure logging for the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Optionally, add console handler explicitly (if basicConfig isn't enough)\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.WARNING)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline # Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit # Stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>income_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \\\n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY   \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY   \n",
       "\n",
       "  income_cat  \n",
       "0          5  \n",
       "1          5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read saved data\n",
    "df = pd.read_parquet(\"../../data/housing-geron.parquet\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use \"income_cat\" for stratified split\n",
    "income_categories_col = df['income_cat']\n",
    "median_house_value_labels = df['median_house_value'] # Series\n",
    "df = df.drop(columns=['income_cat', 'median_house_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "\n",
       "   population  households  median_income ocean_proximity  \n",
       "0       322.0       126.0         8.3252        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014        NEAR BAY  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452600.0\n",
       "1    358500.0\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_house_value_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the columns we will use for the numerical pipeline\n",
    "# The order of columns in Numpy and DataFrame is same\n",
    "numerical_cols = df.drop(columns=['ocean_proximity']).columns.tolist()\n",
    "categorical_col = ['ocean_proximity']\n",
    "ocean_categories = df['ocean_proximity'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from step_2_data_transformer import ca_housing_data_transformer\n",
    "\n",
    "# Prepare the data for the models\n",
    "data_prepared = ca_housing_data_transformer(\n",
    "    numerical_cols, categorical_col, ocean_categories)\n",
    "data_prepared = data_prepared.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels and features from prepared data\n",
    "# The label in data_prepared is the \"label_col\"\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=282)\n",
    "\n",
    "# Get the indices of the training and test sets and split the data\n",
    "for train_index, test_index in stratified_split.split(X=data_prepared,\n",
    "                                                      y=income_categories_col):\n",
    "    X_train = data_prepared[train_index]\n",
    "    y_train = median_house_value_labels[train_index]\n",
    "    X_test = data_prepared[test_index]\n",
    "    y_test = median_house_value_labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (16512, 16), X_test.shape: (4128, 16)\n",
      "y_train.shape: (16512,), y_test.shape: (4128,)\n",
      "data_prepared.shape: (20640, 16)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of X_train, X_test, y_train, y_test\n",
    "print(f\"X_train.shape: {X_train.shape}, X_test.shape: {X_test.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}, y_test.shape: {y_test.shape}\")\n",
    "print(f\"data_prepared.shape: {data_prepared.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remark__ At this point we have a X_train, X_test, y_train, y_test for following data:\n",
    "1. Three new per household columns added: rooms, bedrooms, popolation\n",
    "2. ocean_proximity was encoded using OHE, added 5 more columns\n",
    "3. X_train and X_test were stratifi-cally sampled.\n",
    "\n",
    "What's still remaining is _clipped_ median house value and age.\n",
    " \n",
    " __Imoprtant SKLearn Points:__\n",
    "\n",
    "1. ColumnTransformer rows are independent. They can not depend on each other. At the end output of each step is concatenated. \n",
    "2. The pipeline rows on other hand are exceuted sequenctially. Output of `step-n` is fed to input of `step-n+1`\n",
    "3. In our pipline:\n",
    "    - SimpleImputer:\n",
    "        - Takes in raw numeric data (with possible NaNs)\n",
    "        - Replaces missing values with the median\n",
    "        - Outputs a NumPy array of the same shape\n",
    "    - PerHouseholdFeaturesAdder (custom transformer):\n",
    "        - Takes in the imputed NumPy array\n",
    "        - Adds new columns: e.g., rooms_per_household, etc.\n",
    "        - Outputs an array with more columns\n",
    "    - StandardScaler:\n",
    "        - Receives the expanded feature matrix\n",
    "        - Scales each feature to have zero mean and unit variance\n",
    "        - Outputs a fully scaled matrix (including output labels)\n",
    "4. Stratified sampling needs a reference strat point. In this case it was income category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "First let us train model on all the data (not just train/test). We will see how LinearRegression and DecisionTreeRegressor will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the models\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters(model, model_name):\n",
    "    # Print the parameters of the model\n",
    "    parameters = model.get_params()\n",
    "    print(f\"{model_name} parameters:\")\n",
    "    for key, value in parameters.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in a dictionary\n",
    "prediction_results = []\n",
    "cv_scores = []\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_save_prediction_errors(y_test, y_pred, model_name):\n",
    "    # Print the errors of the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{model_name} MSE: {mse:,.2f}, RMSE: $ {rmse:,.2f}, R2 score: {r2:,.4f}\")\n",
    "    prediction_results.append({\"model_name\": model_name, \"rmse\": rmse, \"r2\": r2, \"mse\": mse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_save_cv_scores(scores, model_name):\n",
    "    # Print the scores of the model\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "    print(f\"{model_name}:\")\n",
    "    mean, std = rmse_scores.mean(), rmse_scores.std()\n",
    "    print(f\"  Scores: {rmse_scores.round(2)}\")\n",
    "    print(f\"  Mean: $ {mean:,.2f}\", end=\" \")\n",
    "    print(f\"  Std Dev: $ {std:,.2f}\")\n",
    "    cv_scores.append({\"model_name\": model_name, \"mean\": mean, \"std\": std})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Run LinearRegression on all the data. And see the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_reg.coef_: [-55320.72 -56255.15  13364.74  -1882.43   7465.25 -46331.97  45752.37\n",
      "  74791.32   6372.1     863.34   9613.22 -27120.68 -23233.93 -60499.22\n",
      " -18806.89 129660.72]\n",
      "lin_reg.intercept_: 241741.59\n",
      "lin_reg.n_features_in_: 16\n",
      "LinearRegression parameters:\n",
      "  copy_X: True\n",
      "  fit_intercept: True\n",
      "  n_jobs: None\n",
      "  positive: False\n"
     ]
    }
   ],
   "source": [
    "# Train on all the data\n",
    "lin_reg = LinearRegression().fit(data_prepared, median_house_value_labels)\n",
    "print(f\"lin_reg.coef_: {lin_reg.coef_.round(2)}\")\n",
    "print(f\"lin_reg.intercept_: {lin_reg.intercept_.round(2)}\")\n",
    "print(f\"lin_reg.n_features_in_: {lin_reg.n_features_in_}\")\n",
    "print_parameters(lin_reg, \"LinearRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression (All Data) MSE: 4,518,787,119.35, RMSE: $ 67,221.92, R2 score: 0.6435\n"
     ]
    }
   ],
   "source": [
    "# Test the model on all the data\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "print_and_save_prediction_errors(y_test, y_pred, \"LinearRegression (All Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression\n",
    "\n",
    "__Remark:__ Our predictions have an average RMSE as $67K. Let us try a `DecisionTreeRegressor`. This is model is very complex and will overfit the data. Note the errors. Train on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor parameters:\n",
      "  ccp_alpha: 0.0\n",
      "  criterion: squared_error\n",
      "  max_depth: None\n",
      "  max_features: None\n",
      "  max_leaf_nodes: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  min_samples_leaf: 1\n",
      "  min_samples_split: 2\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  monotonic_cst: None\n",
      "  random_state: 282\n",
      "  splitter: best\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on all the data\n",
    "tree_reg_model = DecisionTreeRegressor(\n",
    "    random_state=282).fit(data_prepared, median_house_value_labels)\n",
    "print_parameters(tree_reg_model, \"DecisionTreeRegressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor (All Data) MSE: 0.00, RMSE: $ 0.00, R2 score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = tree_reg_model.predict(X_test)\n",
    "print_and_save_prediction_errors(\n",
    "    y_test, y_pred, \"DecisionTreeRegressor (All Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Model\n",
    "Run Lasson on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso parameters:\n",
      "  alpha: 0.1\n",
      "  copy_X: True\n",
      "  fit_intercept: True\n",
      "  max_iter: 100000\n",
      "  positive: False\n",
      "  precompute: False\n",
      "  random_state: 282\n",
      "  selection: cyclic\n",
      "  tol: 0.0001\n",
      "  warm_start: False\n"
     ]
    }
   ],
   "source": [
    "lasso_reg_model = Lasso(alpha=0.1, max_iter=100_000, random_state=282)\n",
    "lasso_reg_model = lasso_reg_model.fit(data_prepared, median_house_value_labels)\n",
    "print_parameters(lasso_reg_model, \"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso (All Data) MSE: 4,518,787,305.01, RMSE: $ 67,221.93, R2 score: 0.6435\n"
     ]
    }
   ],
   "source": [
    "y_pred = lasso_reg_model.predict(X_test)\n",
    "print_and_save_prediction_errors(y_test, y_pred, \"Lasso (All Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge parameters:\n",
      "  alpha: 0.1\n",
      "  copy_X: True\n",
      "  fit_intercept: True\n",
      "  max_iter: None\n",
      "  positive: False\n",
      "  random_state: None\n",
      "  solver: auto\n",
      "  tol: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Fit Ridge on all the data\n",
    "ridge_reg_model = Ridge(alpha=0.1).fit(data_prepared, median_house_value_labels)\n",
    "print_parameters(ridge_reg_model, \"Ridge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (All Data) MSE: 4,518,792,169.70, RMSE: $ 67,221.96, R2 score: 0.6435\n"
     ]
    }
   ],
   "source": [
    "y_pred = ridge_reg_model.predict(X_test)\n",
    "print_and_save_prediction_errors(y_test, y_pred, \"Ridge (All Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest RandomForestRegressor\n",
    "\n",
    "Run the Random Forest on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor parameters:\n",
      "  bootstrap: True\n",
      "  ccp_alpha: 0.0\n",
      "  criterion: squared_error\n",
      "  max_depth: None\n",
      "  max_features: 1.0\n",
      "  max_leaf_nodes: None\n",
      "  max_samples: None\n",
      "  min_impurity_decrease: 0.0\n",
      "  min_samples_leaf: 1\n",
      "  min_samples_split: 2\n",
      "  min_weight_fraction_leaf: 0.0\n",
      "  monotonic_cst: None\n",
      "  n_estimators: 100\n",
      "  n_jobs: None\n",
      "  oob_score: False\n",
      "  random_state: 282\n",
      "  verbose: 0\n",
      "  warm_start: False\n"
     ]
    }
   ],
   "source": [
    "rf_reg_model = RandomForestRegressor(\n",
    "    random_state=282).fit(data_prepared, median_house_value_labels)\n",
    "print_parameters(rf_reg_model, \"RandomForestRegressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor (All Data) MSE: 327,214,542.00, RMSE: $ 18,089.07, R2 score: 0.9742\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = rf_reg_model.predict(X_test)\n",
    "print_and_save_prediction_errors(\n",
    "    y_test, y_pred, \"RandomForestRegressor (All Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try all above models with the X_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all aboved models on all the Training data and test on test data\n",
    "train_lin_reg = LinearRegression().fit(X_train, y_train)\n",
    "train_decision_tree_reg_model = DecisionTreeRegressor(random_state=282).fit(X_train, y_train)\n",
    "train_lasso_reg_model = Lasso(alpha=0.1, max_iter=100_000, random_state=282)\n",
    "train_lasso_reg_model = train_lasso_reg_model.fit(X_train, y_train)\n",
    "train_ridge_reg_model = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "train_rf_reg_model = RandomForestRegressor(random_state=282).fit(X_train, y_train)\n",
    "y_pred = train_lin_reg.predict(X_test)\n",
    "print_and_save_prediction_errors(y_test, y_pred, \"LinearRegression (Train)\")\n",
    "y_pred = train_decision_tree_reg_model.predict(X_test)\n",
    "print_and_save_prediction_errors(y_test, y_pred, \"DecisionTreeRegressor (Train)\")\n",
    "y_pred = train_lasso_reg_model.predict(X_test)\n",
    "print_and_save_prediction_errors(y_test, y_pred, \"Lasso (Train)\")\n",
    "y_pred = train_ridge_reg_model.predict(X_test)\n",
    "print_and_save_prediction_errors(y_test, y_pred, \"Ridge (Train)\")\n",
    "y_pred = train_rf_reg_model.predict(X_test)\n",
    "print_and_save_prediction_errors(y_test, y_pred, \"RandomForestRegressor (Train)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with KFold=10\n",
    "\n",
    "Try the CSV with the Linear Regression Model. Similar to Decision Regressor, redo sclaing at fold level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ca_housing_data_transformer(\n",
    "    numerical_cols, categorical_col, ocean_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv_pipeline = Pipeline([\n",
    "    ('preprocessing', full_pipeline),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "scores = cross_val_score(lr_cv_pipeline, df, median_house_value_labels,\n",
    "                         scoring='neg_mean_squared_error', cv=kfold)\n",
    "print_and_save_cv_scores(scores, \"Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Resgression with KFold = 10\n",
    "__Remark:__ The error on training on training on whole data by DecisionRegression model is ZERO. Clearly model is overfitting. Let us test that by running k-fold test. \n",
    "\n",
    "The scaling parameters above are being computed on the entire dataset. This can lead to inconsistent scaling across folds. We create a new pipeline, rerun it with original data so scaling is done at the fold level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the complete pipeline including the model,\n",
    "tree_cv_pipeline = Pipeline([\n",
    "    ('preprocessing', full_pipeline),\n",
    "    ('model', DecisionTreeRegressor())\n",
    "])\n",
    "scores = cross_val_score(tree_cv_pipeline, df, median_house_value_labels,\n",
    "                         scoring='neg_mean_squared_error', cv=kfold)\n",
    "print_and_save_cv_scores(scores, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Model with KFold=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_pipeline = Pipeline([\n",
    "    ('preprocessing', full_pipeline),\n",
    "    ('model', Lasso(alpha=0.1, max_iter=100_000, random_state=282))\n",
    "])\n",
    "# Apply k-fold cross-validation to the lasso model\n",
    "scores = cross_val_score(lasso_cv_pipeline, df, median_house_value_labels,\n",
    "                         scoring='neg_mean_squared_error', cv=kfold)\n",
    "print_and_save_cv_scores(scores, \"Lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Model with KFold=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Model with KFold = 10\n",
    "ridge_cv_pipeline = Pipeline([\n",
    "    ('preprocessing', full_pipeline),\n",
    "    ('model', Ridge(alpha=0.1))\n",
    "])\n",
    "# Apply k-fold cross-validation to the ridge model\n",
    "scores = cross_val_score(ridge_cv_pipeline, df, median_house_value_labels,\n",
    "                         scoring='neg_mean_squared_error', cv=kfold)\n",
    "print_and_save_cv_scores(scores, \"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with KFold=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the Random Forest on all the data.\n",
    "rf_cv_pipeline = Pipeline([\n",
    "    ('preprocessing', full_pipeline),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "scores = cross_val_score(rf_cv_pipeline, df, median_house_value_labels,\n",
    "                         scoring='neg_mean_squared_error', cv=kfold)\n",
    "print_and_save_cv_scores(scores, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results\n",
    "The results of different approaches are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# Print the results\n",
    "print(\"Prediction Results:\")\n",
    "prediction_results_sorted = sorted(prediction_results, key=lambda x: x['model_name'])\n",
    "print(tabulate(prediction_results_sorted,\n",
    "      headers='keys', tablefmt='grid', floatfmt=\",.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCV Scores:\")\n",
    "cv_scores_sorted = sorted(cv_scores, key=lambda x: x['model_name'])\n",
    "print(tabulate(cv_scores_sorted, headers='keys', tablefmt='grid', floatfmt=\",.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all processed data for model finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally save the processed data and labels\n",
    "df_processed_colnames = ['longitude', 'latitude', 'housing_median_age',\n",
    "                         'total_rooms','total_bedrooms', 'population',\n",
    "                         'households', 'median_income', 'rooms_per_household',\n",
    "                         'population_per_household', 'bedrooms_per_room',\n",
    "                         'NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND']\n",
    "df_processed = pd.DataFrame(data_prepared, columns=df_processed_colnames)\n",
    "df_processed.to_parquet(\"../../data/housing-geron-processed.parquet\")\n",
    "np.save(\"../../data/median_house_value_labels.npy\", median_house_value_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
