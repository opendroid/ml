{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Pipelines\n",
    "Implement routine tasks as a pipelin. The intermediate steps must be a transformer.\n",
    "Transofrmers must implement fit and trandform methods.\n",
    "\n",
    "Note the while the input features are automatically scaled by the pipeline, the\n",
    "predictions are not scaled back to original value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CA housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_set: (20640, 8), features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "target: (20640,), target_names: ['MedHouseVal']\n"
     ]
    }
   ],
   "source": [
    "data_set = fetch_california_housing()\n",
    "print(f\"data_set: {data_set.data.shape}, features: {data_set.feature_names}\")\n",
    "print(f\"target: {data_set.target.shape}, target_names: {data_set.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "types: <class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>\n",
      "shape: (16512, 8), (4128, 8), (16512,), (4128,)\n"
     ]
    }
   ],
   "source": [
    "# Convert to test and training, mising DataFrame and np.array\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_set.data, data_set.target, test_size=0.2, random_state=42)\n",
    "print(f\"types: {type(X_train)}, {type(X_test)}, {type(y_train)}, {type(y_test)}\")\n",
    "print(f\"shape: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different scalars. Note that the target is not scaled.\n",
    "\n",
    "# Latitude and Longitude are applied StandardScaler\n",
    "# Get the transform to be applied to the [:, -2:]\n",
    "std_scaler = StandardScaler().fit(X_train[:, -2:])\n",
    "# Remaining features are applied MinMaxScaler, all positive values\n",
    "minmax_scaler = MinMaxScaler().fit(X_train[:, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_scaler: [  35.64314922 -119.58229046], [2.1366006  2.00559281]\n"
     ]
    }
   ],
   "source": [
    "# Print the scalers parameters\n",
    "print(f\"std_scaler: {std_scaler.mean_}, {std_scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the scalers\n",
    "def preprocessor(X):\n",
    "    A = deepcopy(X)\n",
    "    A[:, -2:] = std_scaler.transform(A[:, -2:])\n",
    "    A[:, :-2] = minmax_scaler.transform(A[:, :-2])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our transformer\n",
    "our_transformer = FunctionTransformer(preprocessor)\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', our_transformer),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_and_print_results(p, X_train, X_test, y_train, y_test):\n",
    "    p.fit(X_train, y_train)\n",
    "    p.fit(X_test, y_test)\n",
    "    y_train_pred = p.predict(X_train)\n",
    "    y_test_pred = p.predict(X_test)\n",
    "    abs_error_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    abs_error_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    print(f\"abs error train: {abs_error_train.mean()}, abs error test: {abs_error_test.mean()}\")\n",
    "    print(f\"MSE train: {mse_train}, MSE test: {mse_test}\")\n",
    "    print(f\"R2 train: {r2_train}, R2 test: {r2_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs error train: 0.5342218724337053, abs error test: 0.5289426614283463\n",
      "MSE train: 0.987610851126717, MSE test: 0.5293336127912476\n",
      "R2 train: 0.2612006670839664, R2 test: 0.596054650433006\n"
     ]
    }
   ],
   "source": [
    "fit_model_and_print_results(pipeline, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
