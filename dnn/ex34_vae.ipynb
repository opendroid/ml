{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f543fa7",
   "metadata": {
    "id": "6f543fa7"
   },
   "source": [
    "# Training Variational Autoencoders Using TensorFlow2.X and Keras\n",
    "\n",
    "- This notebook focuses on training a variational autoencoder.\n",
    "- The Fashion MNIST dataset will be utilized due to its lightweight nature.\n",
    "- This assists learners to learn key concepts in VAE training without lengthy training processes or GPU dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_mRfo45KCCHh",
   "metadata": {
    "id": "_mRfo45KCCHh"
   },
   "source": [
    "## Step 1: Import Required Libraries\n",
    "- Import necessary libraries and modules for numerical computations, operating system interactions, data visualization, and deep learning.\n",
    "- The OS module is imported to interact with the operating system.\n",
    "- The **%matplotlib inline** is a Jupyter Notebook magic command that enables inline plotting.\n",
    "- TensorFlow is imported as the main deep learning framework.\n",
    "- Keras is imported from TensorFlow to utilize the Keras API for building and training models.\n",
    "- An assertion is made to ensure that the TensorFlow version is 2.0 or higher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771497c5-dcf4-4d71-81c5-70323c753c0e",
   "metadata": {
    "id": "771497c5-dcf4-4d71-81c5-70323c753c0e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "assert tf.__version__>=\"2.0\"\n",
    "K = keras.backend # backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f18eae",
   "metadata": {
    "id": "93f18eae"
   },
   "source": [
    "## Step 2: Load the Fashion MNIST Dataset and Split It into Training and Testing Sets\n",
    "- Fashion MNIST Dataset is available in Keras and can be used from the Keras library instead of explicitly downloading it from the source. After downloading the dataset, normalize it by diving 255 and split the dataset\n",
    "- Convert the pixel values to floating-point numbers between 0 and 1\n",
    "- Split the training set into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc49ec99",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752539615791,
     "user": {
      "displayName": "Fabien Marpeau",
      "userId": "15210978490258687001"
     },
     "user_tz": 300
    },
    "id": "fc49ec99"
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "jmWDGR6oAOYe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmWDGR6oAOYe",
    "outputId": "b1764263-93d0-4a5a-ff88-6c48aedf5c85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7372830",
   "metadata": {
    "id": "b7372830"
   },
   "source": [
    "## Step 3: Visualize Original and Reconstructed Images Using a Model\n",
    "- Plot the image using a binary color map\n",
    "- Generate reconstructions using the model for a specified number of images\n",
    "- Create a figure with subplots to display the original images and their reconstructions\n",
    "- Plot the original image in the first row of subplots\n",
    "- Plot the reconstructed image in the second row of subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abc75e5c",
   "metadata": {
    "id": "abc75e5c"
   },
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_output(model, images=X_valid, n_images=10):\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79466c",
   "metadata": {
    "id": "8a79466c"
   },
   "source": [
    "## Step 4: Implement Gaussian Sampling Layer for a Variational Autoencoder\n",
    "- This function is used for sampling the code from a standard normal distribution with a given mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76424f29",
   "metadata": {
    "id": "76424f29"
   },
   "outputs": [],
   "source": [
    "class gaussian_sample(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i5rYZj4dGtin",
   "metadata": {
    "id": "i5rYZj4dGtin"
   },
   "source": [
    "## Step 5: Set the Random Seed for Both Tensorflow and Numpy to 50\n",
    "- Set the seed to make sure that results are consistent and replicable\n",
    "- Input embedding size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c81d4a",
   "metadata": {
    "id": "32c81d4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "latent_size = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36838d9b",
   "metadata": {
    "id": "36838d9b"
   },
   "source": [
    "## Step 6: Define the Encoder of VAE\n",
    "- Define the input and hidden layers for the encoder with the number of nodes in each layer as well as the activation function to be used.\n",
    "- After calculating the mean and standard deviation, we use **gaussian_sample** layer to produce the sampled coding.\n",
    "- Create an encoder that outputs sampled embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c248751",
   "metadata": {
    "id": "1c248751"
   },
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=[28, 28])\n",
    "z = keras.layers.Flatten()(inputs)\n",
    "z = keras.layers.Dense(250, activation=\"relu\")(z)\n",
    "z = keras.layers.Dense(150, activation=\"relu\")(z)\n",
    "\n",
    "latent_mean = keras.layers.Dense(latent_size)(z)\n",
    "latent_log_var = keras.layers.Dense(latent_size)(z)\n",
    "\n",
    "\n",
    "latent = gaussian_sample()([latent_mean, latent_log_var])\n",
    "vae_encoder = keras.models.Model(\n",
    "    inputs=[inputs], outputs=[latent_mean, latent_log_var, latent])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014870c9",
   "metadata": {
    "id": "014870c9"
   },
   "source": [
    "## Step 7: Define the Decoder\n",
    "- Define the input, hidden, and output layers of the decoder\n",
    "- Output of the decoder must be reshaped to the same dimensions as the encoder's input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f211fe6f",
   "metadata": {
    "id": "f211fe6f"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = keras.layers.Input(shape=[latent_size])\n",
    "x = keras.layers.Dense(150, activation=\"relu\")(decoder_inputs)\n",
    "x = keras.layers.Dense(250, activation=\"relu\")(x)\n",
    "x = keras.layers.Dense(28*28, activation=\"sigmoid\")(x)\n",
    "outputs = keras.layers.Reshape([28, 28])(x)\n",
    "vae_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34261a15",
   "metadata": {
    "id": "34261a15"
   },
   "source": [
    "## Step 8: Build the Autoencoder\n",
    "- Use the encoder to generate the sampled embeddings\n",
    "- Provide sampled embeddings as the only input to the decoder\n",
    "- Create the final VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef7a5dfd",
   "metadata": {
    "id": "ef7a5dfd"
   },
   "outputs": [],
   "source": [
    "e_mean, e_log_var, latent = vae_encoder(inputs)\n",
    "reconstructions = vae_decoder(latent)\n",
    "variational_ae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda612a",
   "metadata": {
    "id": "8dda612a"
   },
   "source": [
    "## Step 9: Define the Loss, Compile the Model, and Kick-off the Training\n",
    "- Generate sampled embeddings using the encoder\n",
    "- Encode the input data to obtain the mean and variance of the latent space\n",
    "- Define a function for sample embeddings from the latent space\n",
    "- The sampled_embeddings variable now contains the generated embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a1029f3",
   "metadata": {
    "id": "4a1029f3"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m latent_loss = -\u001b[32m0.5\u001b[39m * K.sum(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[32m1\u001b[39m + latent_log_var - \u001b[43mK\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_log_var\u001b[49m\u001b[43m)\u001b[49m - K.square(latent_mean),\n\u001b[32m      3\u001b[39m     axis=-\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m variational_ae.add_loss(K.mean(latent_loss) / \u001b[32m784.\u001b[39m)\n\u001b[32m      5\u001b[39m variational_ae.compile(loss=\u001b[33m\"\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m\"\u001b[39m, optimizer=\u001b[33m\"\u001b[39m\u001b[33madam\u001b[39m\u001b[33m\"\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/python3-code/ml/.venv/lib/python3.11/site-packages/keras/src/legacy/backend.py:860\u001b[39m, in \u001b[36mexp\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mkeras._legacy.backend.exp\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexp\u001b[39m(x):\n\u001b[32m    859\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"DEPRECATED.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m860\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/python3-code/ml/.venv/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/python3-code/ml/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/python3-code/ml/.venv/lib/python3.11/site-packages/keras/src/backend/common/keras_tensor.py:156\u001b[39m, in \u001b[36mKerasTensor.__tf_tensor__\u001b[39m\u001b[34m(self, dtype, name)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mused when constructing Keras Functional models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand `keras.ops`). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    165\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    171\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    172\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    173\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    175\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "latent_loss = -0.5 * K.sum(\n",
    "1 + latent_log_var - K.exp(latent_log_var) - K.square(latent_mean),\n",
    "    axis=-1)\n",
    "variational_ae.add_loss(K.mean(latent_loss) / 784.)\n",
    "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "history = variational_ae.fit(X_train, X_train, epochs=50, batch_size=128,\n",
    "                             validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_DV3QFjFISZK",
   "metadata": {
    "id": "_DV3QFjFISZK"
   },
   "source": [
    "##  Step 10: Display the Output\n",
    "- This function likely generates reconstructions of the input images using the model and plots them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab7280",
   "metadata": {
    "id": "54ab7280"
   },
   "outputs": [],
   "source": [
    "show_output(variational_ae)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e03607",
   "metadata": {
    "id": "80e03607"
   },
   "source": [
    "## Step 11: Generate a Few Images Using Trained VAE\n",
    "- Calculate the number of columns for subplots\n",
    "- Calculate the number of rows for subplots\n",
    "- Remove the last dimension if it's one\n",
    "- Create a figure with the specified size\n",
    "- Create a subplot for each image\n",
    "- Plot the image using a binary color map\n",
    "- Turn off the axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23590cee",
   "metadata": {
    "id": "23590cee"
   },
   "outputs": [],
   "source": [
    "def plot_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_6HtNemuJQRc",
   "metadata": {
    "id": "_6HtNemuJQRc"
   },
   "source": [
    "## Step 12: Display the Generated Images in a Grid with Four Columns\n",
    "- Set the TensorFlow random seed to 50\n",
    "- Generate random embeddings\n",
    "- Decode embeddings to generate images\n",
    "- Plot the generated images in a grid of four columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e9f6e",
   "metadata": {
    "id": "299e9f6e"
   },
   "outputs": [],
   "source": [
    "#tf.random.set_seed(50)\n",
    "\n",
    "new_inputs = tf.random.normal(shape=[1, latent_size],mean=0.0,stddev=1) # Normal distribution with mu=0 and sigma=2\n",
    "images = vae_decoder(new_inputs).numpy() # Use the defined, trained decoder only\n",
    "plot_images(images, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b7c45",
   "metadata": {
    "id": "514b7c45"
   },
   "source": [
    "Congratulations! You've trained and tested a variational autoencoder."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
