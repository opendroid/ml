{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0YnaxeLGCY4"
   },
   "source": [
    "# __Assisted Practice: Training Deep Neural Networks on TensorFlow__\n",
    "Building Deep Neural Networks on TensorFlow refers to the process of designing and constructing neural network models using the TensorFlow framework. This involves defining the architecture of the neural network, selecting appropriate layers and activation functions, specifying the optimization algorithm, and training the model using data.\n",
    "\n",
    "Let's understand how to build and train a neural network using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saSuWUrGGPIa"
   },
   "source": [
    "\n",
    "\n",
    "## Steps to be followed:\n",
    "1. Import the required libraries\n",
    "2. Load and inspect the data\n",
    "3. Build the model\n",
    "4. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkfqjK31CXXV"
   },
   "source": [
    "### Step 1: Import the required libraries\n",
    "\n",
    "- Import Pandas and NumPy packages.\n",
    "- Import the TensorFlow package, which is used for text-based applications, image recognition, voice search, and many more.\n",
    "- Import the Python package cv2, which is used for computer vision and image processing.\n",
    "- Import the Python package matplotlib, which sets the padding between and around the subplots as well as the figure size.\n",
    "- Import necessary libraries and modules for building a deep learning model using TensorFlow. It includes modules for convolutional and pooling layers, dropout, flattening, and dense layers.\n",
    "- Import other libraries for data manipulation, visualization, and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qz6slja9GCY8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib\n",
    "\n",
    "from dnn_helpers import get_all_callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYhwB5u8GCY-"
   },
   "source": [
    "### Step 2: Load and inspect the data\n",
    "\n",
    "\n",
    "- Load the Boston Housing dataset using the **keras.datasets.boston_housing.load_data()** function.\n",
    "- Split the dataset into two sets: the training set **train_features** and **train_labels** and the testing set **test_features** and **test_labels**.\n",
    "- The training set contains input features (for example, crime rate and number of rooms) and corresponding target labels (for example, the median value of owner-occupied homes).\n",
    "- The testing set is used to evaluate the trained model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1716013014913,
     "user": {
      "displayName": "Vikas Singh",
      "userId": "04375885343580620832"
     },
     "user_tz": -330
    },
    "id": "KaFEYTKKGCZA",
    "outputId": "e810f225-f9b4-432c-92a6-e12429df75d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "(train_features, train_labels), (test_features, test_labels) = keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7cf4yntLbEK"
   },
   "source": [
    "- The mean **train_mean** and standard deviation **train_std** are calculated along the columns **axis=0** of the **train_features** array.\n",
    "- Then, the **train_features** array is standardized by subtracting the mean and dividing the resultant by the standard deviation.\n",
    "- This standardization process ensures that the features have a zero mean and unit variance, which can help improve the training performance and convergence of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "duafEb2UGCZA"
   },
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_features, axis=0)\n",
    "train_std = np.std(train_features, axis=0)\n",
    "train_features = (train_features - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1716013014913,
     "user": {
      "displayName": "Vikas Singh",
      "userId": "04375885343580620832"
     },
     "user_tz": -330
    },
    "id": "Xo9x5HkuGCZB",
    "outputId": "7f8bf1c4-8134-4bad-aafe-4bf1569591cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.27224633, -0.48361547, -0.43576161, -0.25683275, -0.1652266 ,\n",
       "        -0.1764426 ,  0.81306188,  0.1166983 , -0.62624905, -0.59517003,\n",
       "         1.14850044,  0.44807713,  0.8252202 ]),\n",
       " (404, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0], train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_ZxZUEeF8iN"
   },
   "source": [
    " __Observation:__\n",
    "\n",
    "\n",
    "- Here, we can see a few Boston housing datasets.\n",
    "- The given array represents a multi-dimensional array containing numerical values.\n",
    "- Each row in the array corresponds to a set of features or data points, while each column represents a specific feature or variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5fZchhYFbBZ"
   },
   "source": [
    "### Step 3: Build the Model\n",
    "Building the neural network requires:\n",
    "- Configuring the layers of the model and compiling the model.\n",
    "- Stacking a few layers together using **keras.Sequential**.\n",
    "- Configuring the loss function, optimizer, and metrics to monitor.\n",
    "These are added during the model's compile step.\n",
    "\n",
    "\n",
    "\n",
    "Terminologies:\n",
    "- The **Loss** function measures how accurate the model is during training; we want to minimize this with the optimizer.\n",
    "- One must **Optimize** how the model is updated based on the data it sees and its loss function.\n",
    "- **Metrics** are used to monitor the training and testing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kg01bCMMGCZC"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=[len(train_features[0])]),\n",
    "        Dense(20, activation=tf.nn.relu),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(),\n",
    "                  loss='mae',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkM_Ixa_GCZD"
   },
   "source": [
    "### Step 4: Train the model\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "\n",
    "- Define a custom callback class **PrintDot**, which prints a dot for every epoch during training.\n",
    "\n",
    "- Create an instance of the model using the **build_model** function.\n",
    "\n",
    "- Create an instance of EarlyStopping callback, which monitors the validation loss and stops training if it doesn't improve after a certain number of epochs (specified by patience).\n",
    "\n",
    "- Train the model using the training features and labels. It runs for 200 epochs, with a validation split of 0.1 (10% of the training data used for validation). The callbacks parameter includes **early_stop** and **PrintDot** callbacks.\n",
    "\n",
    "- Create a Pandas **DataFrame hist** from the history object returned by the model.fit method. It contains the recorded training and validation metrics.\n",
    "\n",
    "- Extract the last value of the validation mean absolute error (MAE) from the hist DataFrame and assign it to the variable mae_final.\n",
    "\n",
    "- Print the final MAE on the validation set, rounded to three decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22365,
     "status": "ok",
     "timestamp": 1716013037273,
     "user": {
      "displayName": "Vikas Singh",
      "userId": "04375885343580620832"
     },
     "user_tz": -330
    },
    "id": "8WocKoO9GCZE",
    "outputId": "5bcce83c-9280-4d80-98d5-0393c2dc2954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch= 0 Train loss= 21.985206604003906\n",
      ".......................................................................................................................................................................................................\n",
      "Epoch= 200 Train loss= 2.4427618980407715\n",
      ".......................................................................................................................................................................................................\n",
      "Epoch= 400 Train loss= 1.9485777616500854\n",
      ".......................................................................................................................................................................................................\n",
      "Epoch= 600 Train loss= 1.8125717639923096\n",
      "......................\n",
      "Final  Mean absolute  Error on validation set: 2.57\n"
     ]
    }
   ],
   "source": [
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "\n",
    "        if epoch % 200 == 0:\n",
    "            print('\\nEpoch=', epoch, 'Train loss=', logs['loss'])\n",
    "        else:\n",
    "            print(\".\", end=\"\")\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "history = model.fit(train_features, train_labels, epochs=5_000, verbose=0, validation_split = 0.2,\n",
    "                    callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "mae_final = float(hist['val_mean_absolute_error'].tail(1).iloc[0])\n",
    "\n",
    "print()\n",
    "print('Final  Mean absolute  Error on validation set: {}'.format(round(mae_final, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r7uOD6jLYx-"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "As shown, the final mean absolute error on the validation set is 2.596."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZeUxYF9HML2"
   },
   "source": [
    "- Normalize the test features based on the mean and standard deviation of the training set.\n",
    "- Evaluate the model's performance on the normalized test features and prints the mean absolute error (MAE) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1716013037274,
     "user": {
      "displayName": "Vikas Singh",
      "userId": "04375885343580620832"
     },
     "user_tz": -330
    },
    "id": "LQbYz8kMGCZE",
    "outputId": "714cd6c4-dcfd-494a-d043-5dedd197ab4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3342 - mean_absolute_error: 2.3342\n",
      " Mean absolute  Error on test set: 2.594\n"
     ]
    }
   ],
   "source": [
    "test_features_norm = (test_features - train_mean) / train_std\n",
    "mae,  _ = model.evaluate(test_features_norm, test_labels)\n",
    "#rmae = np.sqrt(mae)\n",
    "print(' Mean absolute  Error on test set: {}'.format(round(mae, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">905</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m905\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">604</span> (2.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m604\u001b[0m (2.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCrX2XQzL1x3"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "The output indicates the following:\n",
    "\n",
    "- The evaluation was performed on 4 data points.\n",
    "- The loss value (mean squared error) on the test set is 3.1237.\n",
    "- The mean absolute error on the test set is also 3.1237.\n",
    "- The mean absolute error, when rounded, is 3.124.\n",
    "\n",
    "In summary, the model achieved a loss value of 3.1237 and a mean absolute error of 3.1237, which translates to a mean absolute error of approximately 3.124."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
